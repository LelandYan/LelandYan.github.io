<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/ioc32x32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/ioc16x16.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Pisces","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
<meta property="og:type" content="website">
<meta property="og:title" content="LelandYan">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="LelandYan">
<meta property="og:description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="LelandYan">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="matlab">
<meta property="article:tag" content="C++">
<meta property="article:tag" content="java">
<meta property="article:tag" content="django">
<meta property="article:tag" content="tensorflow">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false
  };
</script>

  <title>LelandYan</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="LelandYan" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LelandYan</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">一个沉默的人</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/LelandYan" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/04/2020-3-3-matplotlib_learning-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LelandYan">
      <meta itemprop="description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LelandYan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/04/2020-3-3-matplotlib_learning-2020/" class="post-title-link" itemprop="url">matplotlib防止中文乱码</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-04 12:08:25 / 修改时间：14:23:30" itemprop="dateCreated datePublished" datetime="2020-03-04T12:08:25+08:00">2020-03-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hey"><a href="#Hey" class="headerlink" title="Hey"></a>Hey</h1><blockquote>
<p>Machine Learning notes</p>
</blockquote>
<h1 id="matplotlib防止中文乱码"><a href="#matplotlib防止中文乱码" class="headerlink" title="matplotlib防止中文乱码"></a>matplotlib防止中文乱码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘图时候防止在图像的中文乱码</span></span><br><span class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'simHei'</span>]</span><br><span class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/04/2020-3-3-matrix_derivative-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LelandYan">
      <meta itemprop="description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LelandYan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/04/2020-3-3-matrix_derivative-2020/" class="post-title-link" itemprop="url">矩阵求导</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-04 12:08:25 / 修改时间：14:30:43" itemprop="dateCreated datePublished" datetime="2020-03-04T12:08:25+08:00">2020-03-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hey"><a href="#Hey" class="headerlink" title="Hey"></a>Hey</h1><blockquote>
<p>Machine Learning notes</p>
</blockquote>
<h1 id="矩阵求导"><a href="#矩阵求导" class="headerlink" title="矩阵求导"></a>矩阵求导</h1><ol>
<li>向量关于标量X的求导<script type="math/tex; mode=display">
\left[
 \begin{matrix}
   y_1 \\
   y_2 \\
   \vdots \\
   y_n
  \end{matrix}
  \right]</script></li>
</ol>
<p>   经过求导后</p>
<script type="math/tex; mode=display">
   \left[
    \begin{matrix}
     \frac{\partial y_1}{\partial x} \\
      \frac{\partial y_2}{\partial x} \\
      \vdots \\
      \frac{\partial y_n}{\partial x}
     \end{matrix}
     \right]</script><ol>
<li><p>矩阵对标量X的求导-和对向量的求导使同理的</p>
</li>
<li><p>矩阵对向量X求导</p>
</li>
</ol>
<script type="math/tex; mode=display">
   A=\left[
   \begin{matrix}
    a11      & a12      & \cdots & a1n      \\
    a21      & a22      & \cdots & a2n      \\
    \vdots & \vdots & \ddots & \vdots \\
    am1      & am2      & \cdots & am      \\
   \end{matrix}
   \right]</script><script type="math/tex; mode=display">
   \vec{X}=\begin{Bmatrix}
     x_1 \\
      x_2 \\
      \vdots \\
      x_n
     \end{Bmatrix} \tag{5}</script><script type="math/tex; mode=display">
   \vec{Y} = \vec{A}\cdot\vec{X}=\left[
   \begin{matrix}
    a11\cdot x1 + a12\cdot\ x2 \cdot + a1n \cdot xn \\
    a21\cdot x1 + a22\cdot\ x2 \cdot + a2n \cdot xn \\
    \vdots &  \\
    am1\cdot x1 + am2\cdot\ x2 \cdot + amn \cdot xn \\
   \end{matrix}
   \right]</script><script type="math/tex; mode=display">
\frac{\partial \vec{Y}}{\partial \vec{X}}=\left[
   \begin{matrix}
    a11      & a21      & \cdots & am1      \\
    a12      & a22      & \cdots & am2      \\
    \vdots & \vdots & \ddots & \vdots \\
    a1n      & a2n      & \cdots & amn      \\
   \end{matrix}
   \right]=A^T</script><p><img src="/images/matrix.png" alt=""></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/04/2020-3-3-mult_classifition-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LelandYan">
      <meta itemprop="description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LelandYan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/04/2020-3-3-mult_classifition-2020/" class="post-title-link" itemprop="url">如何处理多分类问题</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-04 12:08:25 / 修改时间：14:02:29" itemprop="dateCreated datePublished" datetime="2020-03-04T12:08:25+08:00">2020-03-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hey"><a href="#Hey" class="headerlink" title="Hey"></a>Hey</h1><blockquote>
<p>Machine Learning notes</p>
</blockquote>
<h1 id="如何处理多分类问题"><a href="#如何处理多分类问题" class="headerlink" title="如何处理多分类问题"></a>如何处理多分类问题</h1><h2 id="有关多分类问题有两种方法"><a href="#有关多分类问题有两种方法" class="headerlink" title="有关多分类问题有两种方法"></a>有关多分类问题有两种方法</h2><p>二分类器只能区分两个类，而多类分类器（也被叫做多项式分类器）可以区分多于两个类。</p>
<p>一些算法（比如随机森林分类器或者朴素贝叶斯分类器）可以直接处理多类分类问题。其他一些算法（比如 SVM 分类器或者线性分类器）则是严格的二分类器。然后，有许多策略可以让你用二分类器去执行多类分类。</p>
<p>举例子，创建一个可以将图片分成 10 类（从 0 到 9）的系统的一个方法是：训练10个二分类器，每一个对应一个数字（探测器 0，探测器 1，探测器 2，以此类推）。然后当你想对某张图片进行分类的时候，让每一个分类器对这个图片进行分类，选出决策分数最高的那个分类器。这叫做“一对所有”（OvA）策略（也被叫做“一对其他”）。</p>
<p>另一个策略是对每一对数字都训练一个二分类器：一个分类器用来处理数字 0 和数字 1，一个用来处理数字 0 和数字 2，一个用来处理数字 1 和 2，以此类推。这叫做“一对一”（OvO）策略。如果有 N 个类。你需要训练<code>N*(N-1)/2</code>个分类器。对于 MNIST 问题，需要训练 45 个二分类器！当你想对一张图片进行分类，你必须将这张图片跑在全部45个二分类器上。然后看哪个类胜出。OvO 策略的主要优点是：每个分类器只需要在训练集的部分数据上面进行训练。这部分数据是它所需要区分的那两个类对应的数据。</p>
<p>一些算法（比如 SVM 分类器）在训练集的大小上很难扩展，所以对于这些算法，OvO 是比较好的，因为它可以在小的数据集上面可以更多地训练，较之于巨大的数据集而言。但是，对于大部分的二分类器来说，OvA 是更好的选择。</p>
<p>Scikit-Learn 可以探测出你想使用一个二分类器去完成多分类的任务，它会自动地执行 OvA（除了 SVM 分类器，它使用 OvO）。让我们试一下<code>SGDClassifier</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.fit(X_train, y_train) <span class="comment"># y_train, not y_train_5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.predict([some_digit])</span><br><span class="line">array([ <span class="number">5.</span>])</span><br></pre></td></tr></table></figure>
<p>很容易。上面的代码在训练集上训练了一个<code>SGDClassifier</code>。这个分类器处理原始的目标class，从 0 到 9（<code>y_train</code>），而不是仅仅探测是否为 5 （<code>y_train_5</code>）。然后它做出一个判断（在这个案例下只有一个正确的数字）。在幕后，Scikit-Learn 实际上训练了 10 个二分类器，每个分类器都产到一张图片的决策数值，选择数值最高的那个类。</p>
<p>为了证明这是真实的，你可以调用<code>decision_function()</code>方法。不是返回每个样例的一个数值，而是返回 10 个数值，一个数值对应于一个类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_digit_scores = sgd_clf.decision_function([some_digit])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_digit_scores</span><br><span class="line">array([[<span class="number">-311402.62954431</span>, <span class="number">-363517.28355739</span>, <span class="number">-446449.5306454</span> ,</span><br><span class="line">        <span class="number">-183226.61023518</span>, <span class="number">-414337.15339485</span>, <span class="number">161855.74572176</span>,</span><br><span class="line">        <span class="number">-452576.39616343</span>, <span class="number">-471957.14962573</span>, <span class="number">-518542.33997148</span>,</span><br><span class="line">        <span class="number">-536774.63961222</span>]])</span><br></pre></td></tr></table></figure>
<p>最高数值是对应于类别 5 ：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argmax(some_digit_scores)</span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.classes_</span><br><span class="line">array([ <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>, <span class="number">7.</span>, <span class="number">8.</span>, <span class="number">9.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.classes_[<span class="number">5</span>]</span><br><span class="line"><span class="number">5.0</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>一个分类器被训练好了之后，它会保存目标类别列表到它的属性<code>classes_</code> 中去，按照值排序。在本例子当中，在<code>classes_</code> 数组当中的每个类的索引方便地匹配了类本身，比如，索引为 5 的类恰好是类别 5 本身。但通常不会这么幸运。</p>
</blockquote>
<p>如果你想强制 Scikit-Learn 使用 OvO 策略或者 OvA 策略，你可以使用<code>OneVsOneClassifier</code>类或者<code>OneVsRestClassifier</code>类。创建一个样例，传递一个二分类器给它的构造函数。举例子，下面的代码会创建一个多类分类器，使用 OvO 策略，基于<code>SGDClassifier</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsOneClassifier</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=<span class="number">42</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ovo_clf.fit(X_train, y_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ovo_clf.predict([some_digit])</span><br><span class="line">array([ <span class="number">5.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(ovo_clf.estimators_)</span><br><span class="line"><span class="number">45</span></span><br></pre></td></tr></table></figure>
<p>训练一个<code>RandomForestClassifier</code>同样简单：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_clf.fit(X_train, y_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_clf.predict([some_digit])</span><br><span class="line">array([ <span class="number">5.</span>])</span><br></pre></td></tr></table></figure>
<p>这次 Scikit-Learn 没有必要去运行 OvO 或者 OvA，因为随机森林分类器能够直接将一个样例分到多个类别。你可以调用<code>predict_proba()</code>，得到样例对应的类别的概率值的列表：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_clf.predict_proba([some_digit])</span><br><span class="line">array([[ <span class="number">0.1</span>, <span class="number">0.</span> , <span class="number">0.</span> , <span class="number">0.1</span>, <span class="number">0.</span> , <span class="number">0.8</span>, <span class="number">0.</span> , <span class="number">0.</span> , <span class="number">0.</span> , <span class="number">0.</span> ]])</span><br></pre></td></tr></table></figure>
<p>你可以看到这个分类器相当确信它的预测：在数组的索引 5 上的 0.8，意味着这个模型以 80% 的概率估算这张图片代表数字 5。它也认为这个图片可能是数字 0 或者数字 3，分别都是 10% 的几率。</p>
<p>现在当然你想评估这些分类器。像平常一样，你想使用交叉验证。让我们用<code>cross_val_score()</code>来评估<code>SGDClassifier</code>的精度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(sgd_clf, X_train, y_train, cv=<span class="number">3</span>, scoring=<span class="string">"accuracy"</span>)</span><br><span class="line">array([ <span class="number">0.84063187</span>, <span class="number">0.84899245</span>, <span class="number">0.86652998</span>])</span><br></pre></td></tr></table></figure>
<p>在所有测试折（test fold）上，它有 84% 的精度。如果你是用一个随机的分类器，你将会得到 10% 的正确率。所以这不是一个坏的分数，但是你可以做的更好。举例子，简单将输入正则化，将会提高精度到 90% 以上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler = StandardScaler()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(sgd_clf, X_train_scaled, y_train, cv=<span class="number">3</span>, scoring=<span class="string">"accuracy"</span>)</span><br><span class="line">array([ <span class="number">0.91011798</span>, <span class="number">0.90874544</span>, <span class="number">0.906636</span> ])</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/04/2020-3-3-regulation_overfitting-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LelandYan">
      <meta itemprop="description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LelandYan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/04/2020-3-3-regulation_overfitting-2020/" class="post-title-link" itemprop="url">Addressing overfitting</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-04 12:08:25 / 修改时间：14:29:11" itemprop="dateCreated datePublished" datetime="2020-03-04T12:08:25+08:00">2020-03-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hey"><a href="#Hey" class="headerlink" title="Hey"></a>Hey</h1><blockquote>
<p>Machine Learning notes</p>
</blockquote>
<h1 id="Addressing-overfitting"><a href="#Addressing-overfitting" class="headerlink" title="Addressing overfitting"></a>Addressing overfitting</h1><h3 id="options"><a href="#options" class="headerlink" title="options:"></a>options:</h3><p>​    1 .Reduce number of features</p>
<p>​        Manually select which features to keep</p>
<p>​        Model selection algorithm()</p>
<p>​    2.Regularization</p>
<p>​        Keep all the features,but reduce magnitude/value parameters</p>
<p>​        Works well when we have a lot of    features,each of which contributes a bit ot predicting        </p>
<p>​    small values for parameters</p>
<p>​    3. Regularized linear regression<br>   <img src="/images/regulation.png" alt=""></p>
<ol>
<li>Gradient descent<br><img src="/images/regularization_gradient.png" alt="Image text"></li>
</ol>
<ol>
<li><p>normalization equation</p>
<ol>
<li><p>奇异矩阵的判断方法：</p>
<p>首先，看这个矩阵是不是方阵（即行数和列数相等的矩阵。若行数和列数不相等，那就谈不上奇异矩阵和非奇异矩阵）。 然后，再看此方阵的行列式| A |是否等于0，若等于0，称矩阵A为奇异矩阵；若不等于0，称矩阵A为非奇异矩阵。 同时，由| A |≠0可知矩阵A可逆，这样可以得出另外一个重要结论:可逆矩阵就是非奇异矩阵，非奇异矩阵也是可逆矩阵。</p>
</li>
</ol>
<p><img src="/images/normalization_regualization.png" alt="Image text"></p>
</li>
</ol>
<p>   <strong>这里一定是可逆的的矩阵，虽然X^TX可能不可逆，但是加入惩罚因子后，其和的行列式不为0，所以其可逆</strong></p>
<ol>
<li><p>regularization logistic regression</p>
<p>logistic regression 和 linear regression 区别在与costFunction和是否使用sigimoid function</p>
<script type="math/tex; mode=display">
J(\theta) = -\frac{ 1 }{ m }[\sum_{ i=1 }^{ m } ({y^{(i)} \log h_\theta(x^{(i)}) + (1-y^{(i)}) \log (1-h_\theta(x^{(i)})})]+\frac{k}{2m}\sum_{ i=1 }^{ n }\theta_j^2</script><p><img src="/images/regulariation_logistic_1545615172826.png" alt="Image text"></p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/04/2020-3-3-sample_data-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LelandYan">
      <meta itemprop="description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LelandYan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/04/2020-3-3-sample_data-2020/" class="post-title-link" itemprop="url">数据集划分</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-04 12:08:25 / 修改时间：14:47:33" itemprop="dateCreated datePublished" datetime="2020-03-04T12:08:25+08:00">2020-03-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hey"><a href="#Hey" class="headerlink" title="Hey"></a>Hey</h1><blockquote>
<p>Machine Learning notes</p>
</blockquote>
<h1 id="样本抽样以及数据集划分"><a href="#样本抽样以及数据集划分" class="headerlink" title="样本抽样以及数据集划分"></a>样本抽样以及数据集划分</h1><h2 id="1-随机取样，将数据集分为训练集和测试集"><a href="#1-随机取样，将数据集分为训练集和测试集" class="headerlink" title="1. 随机取样，将数据集分为训练集和测试集"></a>1. 随机取样，将数据集分为训练集和测试集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一种方法</span></span><br><span class="line"><span class="comment"># 使用sklearn中的train_test_split</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_set, test_set = train_test_split(housing, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种方法</span></span><br><span class="line"><span class="comment"># 当数据的数量是不确定的时候</span></span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_set_check</span><span class="params">(identifier,test_ratio,hash=hashlib.md5)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> hash(np.int64(identifier)).digest()[<span class="number">-1</span>] &lt; <span class="number">256</span> * test_ratio</span><br><span class="line"><span class="comment"># 这样可以避免原本的训练集中的数据进入测试集中 这里的id_column可以是组合的</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_train_test_by_id</span><span class="params">(data,test_ratio,id_column)</span>:</span></span><br><span class="line">    ids = data[id_column]</span><br><span class="line">    in_test_set = ids.apply(<span class="keyword">lambda</span> id_:test_set_check(id_,test_ratio))</span><br><span class="line">    <span class="keyword">return</span> data.loc[~in_test_set],data.loc[in_test_set]</span><br></pre></td></tr></table></figure>
<h2 id="2-分层抽样"><a href="#2-分层抽样" class="headerlink" title="2. 分层抽样"></a>2. 分层抽样</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对数据根据median_income进行分层</span></span><br><span class="line">housing[<span class="string">"income_cat"</span>] = pd.cut(housing[<span class="string">"median_income"</span>],bins=[<span class="number">0</span>,<span class="number">1.5</span>,<span class="number">3.0</span>,<span class="number">4.5</span>,<span class="number">6</span>,np.inf],labels=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line"><span class="comment"># 对每层的数量进行计数</span></span><br><span class="line">housing[<span class="string">"income_cat"</span>].value_counts()</span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">housing[<span class="string">"income_cat"</span>].hist()</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</span><br><span class="line">split = StratifiedShuffleSplit(n_split=<span class="number">1</span>,test_size=<span class="number">0.2</span>,random_state=<span class="number">42</span>)</span><br><span class="line"><span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> split.split(housing,housing[<span class="string">"income_cat"</span>]):</span><br><span class="line">   strat_train_set = housing.loc[train_index]</span><br><span class="line">   srat_test_set = housing.loc[test_index]</span><br><span class="line">strat_test_set[<span class="string">"income_cat"</span>].value_counts() / len(strat_test_set)</span><br><span class="line">housing[<span class="string">"income_cat"</span>].value_count() / len(strat_test_set)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对median_cat进行删除</span></span><br><span class="line"><span class="keyword">for</span> set_ <span class="keyword">in</span> (strat_train_set,strat_test_set):</span><br><span class="line">    set_.drop(<span class="string">"income_cat"</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/04/2020-3-3-spare_matrix-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LelandYan">
      <meta itemprop="description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LelandYan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/04/2020-3-3-spare_matrix-2020/" class="post-title-link" itemprop="url">sklearn稀疏矩阵</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-04 12:08:25 / 修改时间：14:17:55" itemprop="dateCreated datePublished" datetime="2020-03-04T12:08:25+08:00">2020-03-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hey"><a href="#Hey" class="headerlink" title="Hey"></a>Hey</h1><blockquote>
<p>Machine Learning notes</p>
</blockquote>
<h1 id="sklearn稀疏矩阵"><a href="#sklearn稀疏矩阵" class="headerlink" title="sklearn稀疏矩阵"></a>sklearn稀疏矩阵</h1><h3 id="lil-matrix-使用两个列表储存非0元素，data保存每行中的非零元素-rows保存非零元素所在的列。这种格式也很适合逐个添加元素，并且能快速获取行相关的数据。"><a href="#lil-matrix-使用两个列表储存非0元素，data保存每行中的非零元素-rows保存非零元素所在的列。这种格式也很适合逐个添加元素，并且能快速获取行相关的数据。" class="headerlink" title="lil_matrix 使用两个列表储存非0元素，data保存每行中的非零元素,rows保存非零元素所在的列。这种格式也很适合逐个添加元素，并且能快速获取行相关的数据。"></a>lil_matrix 使用两个列表储存非0元素，data保存每行中的非零元素,rows保存非零元素所在的列。这种格式也很适合逐个添加元素，并且能快速获取行相关的数据。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.sparse <span class="keyword">import</span> lil_matrix</span><br><span class="line">l = lil_matrix((<span class="number">6</span>,<span class="number">5</span>))</span><br><span class="line">l[<span class="number">2</span>,<span class="number">3</span>] = <span class="number">1</span></span><br><span class="line">l[<span class="number">3</span>,<span class="number">4</span>] = <span class="number">2</span></span><br><span class="line">l[<span class="number">3</span>,<span class="number">2</span>] = <span class="number">3</span></span><br><span class="line">print(l.toarray())</span><br><span class="line">[[ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">1.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">3.</span>  <span class="number">0.</span>  <span class="number">2.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> l.data</span><br><span class="line">[[] [] [<span class="number">1.0</span>] [<span class="number">3.0</span>, <span class="number">2.0</span>] [] []]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> l.rows</span><br><span class="line">[[] [] [<span class="number">3</span>] [<span class="number">2</span>, <span class="number">4</span>] [] []]</span><br></pre></td></tr></table></figure>
<h3 id="dok-matrix和lil-matrix适用的场景是逐渐添加矩阵的元素。doc-matrix的策略是采用字典来记录矩阵中不为0的元素。自然，字典的key存的是记录元素的位置信息的元祖，value是记录元素的具体值。"><a href="#dok-matrix和lil-matrix适用的场景是逐渐添加矩阵的元素。doc-matrix的策略是采用字典来记录矩阵中不为0的元素。自然，字典的key存的是记录元素的位置信息的元祖，value是记录元素的具体值。" class="headerlink" title="dok_matrix和lil_matrix适用的场景是逐渐添加矩阵的元素。doc_matrix的策略是采用字典来记录矩阵中不为0的元素。自然，字典的key存的是记录元素的位置信息的元祖，value是记录元素的具体值。"></a>dok_matrix和lil_matrix适用的场景是逐渐添加矩阵的元素。doc_matrix的策略是采用字典来记录矩阵中不为0的元素。自然，字典的key存的是记录元素的位置信息的<a href="https://www.baidu.com/s?wd=%E5%85%83%E7%A5%96&amp;tn=24004469_oem_dg&amp;rsv_dl=gh_pl_sl_csd" target="_blank" rel="noopener">元祖</a>，value是记录元素的具体值。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.sparse <span class="keyword">import</span> dok_matrix</span><br><span class="line">S = dok_matrix((<span class="number">5</span>,<span class="number">5</span>), dtype=np.float32)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        S[i,j] = i + j</span><br><span class="line"><span class="comment"># 返回的是非零元素的row_index,column_index</span></span><br><span class="line">S.nonzero()</span><br><span class="line">print(S.toarray())</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/04/2020-3-3-sciPy-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LelandYan">
      <meta itemprop="description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LelandYan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/04/2020-3-3-sciPy-2020/" class="post-title-link" itemprop="url">如何处理不平衡的数据</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-04 12:08:25 / 修改时间：13:53:40" itemprop="dateCreated datePublished" datetime="2020-03-04T12:08:25+08:00">2020-03-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hey"><a href="#Hey" class="headerlink" title="Hey"></a>Hey</h1><blockquote>
<p>Machine Learning notes</p>
</blockquote>
<h1 id="2-5-SciPy中稀疏矩阵"><a href="#2-5-SciPy中稀疏矩阵" class="headerlink" title="2.5 SciPy中稀疏矩阵"></a>2.5 SciPy中稀疏矩阵</h1><p>In [3]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">import numpy as np</span><br></pre></td></tr></table></figure>
<h2 id="2-5-1-介绍"><a href="#2-5-1-介绍" class="headerlink" title="2.5.1 介绍"></a>2.5.1 介绍</h2><p>(密集) 矩阵是:</p>
<ul>
<li>数据对象</li>
<li>存储二维值数组的数据结构</li>
</ul>
<p>重要特征:</p>
<ul>
<li>一次分配所有项目的内存<ul>
<li>通常是一个连续组块，想一想Numpy数组</li>
</ul>
</li>
<li><em>快速</em>访问个项目(*)</li>
</ul>
<h3 id="2-5-1-1-为什么有稀疏矩阵？"><a href="#2-5-1-1-为什么有稀疏矩阵？" class="headerlink" title="2.5.1.1 为什么有稀疏矩阵？"></a>2.5.1.1 为什么有稀疏矩阵？</h3><ul>
<li>内存，增长是n**2</li>
<li>小例子（双精度矩阵）:</li>
</ul>
<p>In [5]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">x &#x3D; np.linspace(0, 1e6, 10)</span><br><span class="line">plt.plot(x, 8.0 * (x**2) &#x2F; 1e6, lw&#x3D;5)   </span><br><span class="line">plt.xlabel(&#39;size n&#39;)</span><br><span class="line">plt.ylabel(&#39;memory [MB]&#39;)</span><br></pre></td></tr></table></figure>
<p>Out[5]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;matplotlib.text.Text at 0x105b08dd0&gt;</span><br></pre></td></tr></table></figure>
<p><img src="https://wizardforcel.gitbooks.io/scipy-lecture-notes/content/img/C3AAAAAElFTkSuQmCC.png" alt="img"></p>
<h3 id="2-5-1-2-稀疏矩阵-vs-稀疏矩阵存储方案"><a href="#2-5-1-2-稀疏矩阵-vs-稀疏矩阵存储方案" class="headerlink" title="2.5.1.2 稀疏矩阵 vs. 稀疏矩阵存储方案"></a>2.5.1.2 稀疏矩阵 vs. 稀疏矩阵存储方案</h3><ul>
<li>稀疏矩阵是一个矩阵，巨大多数是空的</li>
<li>存储所有的0是浪费 -&gt; 只存储非0项目</li>
<li>想一下<strong>压缩</strong></li>
<li>有利: 巨大的内存节省</li>
<li>不利: 依赖实际的存储方案, (*) 通常并不能满足</li>
</ul>
<h3 id="2-5-1-3-典型应用"><a href="#2-5-1-3-典型应用" class="headerlink" title="2.5.1.3 典型应用"></a>2.5.1.3 典型应用</h3><ul>
<li>偏微分方程（PDES）的解<ul>
<li>有限元素法</li>
<li>机械工程、电子、物理…</li>
</ul>
</li>
<li>图论<ul>
<li>（i，j）不是0表示节点i与节点j是联接的</li>
</ul>
</li>
<li>…</li>
</ul>
<h3 id="2-5-1-4-先决条件"><a href="#2-5-1-4-先决条件" class="headerlink" title="2.5.1.4 先决条件"></a>2.5.1.4 先决条件</h3><p>最新版本的</p>
<ul>
<li><code>numpy</code></li>
<li><code>scipy</code></li>
<li><code>matplotlib</code> (可选)</li>
<li><code>ipython</code> (那些增强很方便)</li>
</ul>
<h3 id="2-5-1-5-稀疏结构可视化"><a href="#2-5-1-5-稀疏结构可视化" class="headerlink" title="2.5.1.5 稀疏结构可视化"></a>2.5.1.5 稀疏结构可视化</h3><ul>
<li>matplotlib中的<code>spy()</code></li>
<li>样例绘图:</li>
</ul>
<p><img src="http://scipy-lectures.github.io/_images/graph.png" alt="img"> <img src="http://scipy-lectures.github.io/_images/graph_g.png" alt="img"> <img src="http://scipy-lectures.github.io/_images/graph_rcm.png" alt="img"></p>
<h2 id="2-5-2-存储机制"><a href="#2-5-2-存储机制" class="headerlink" title="2.5.2 存储机制"></a>2.5.2 存储机制</h2><ul>
<li>scipy.sparse中有七类稀疏矩阵:<ol>
<li>csc_matrix: 压缩列格式</li>
<li>csr_matrix: 压缩行格式</li>
<li>bsr_matrix: 块压缩行格式</li>
<li>lil_matrix: 列表的列表格式</li>
<li>dok_matrix: 值的字典格式</li>
<li>coo_matrix: 座标格式 (即 IJV, 三维格式)</li>
<li>dia_matrix: 对角线格式</li>
</ol>
</li>
<li>每一个类型适用于一些任务</li>
<li>许多都利用了由Nathan Bell提供的稀疏工具 C ++ 模块</li>
<li>假设导入了下列模块:</li>
</ul>
<p>In [1]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import scipy.sparse as sparse</span><br><span class="line">import matplotlib.pyplot as plt</span><br></pre></td></tr></table></figure>
<ul>
<li><p>给Numpy用户的</p>
<p>warning</p>
<p>:</p>
<ul>
<li>使用’<em>‘的乘是</em>矩阵相乘* (点积)</li>
<li>并不是Numpy的一部分!<ul>
<li>向Numpy函数传递一个稀疏矩阵希望一个ndarray/矩阵是没用的</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2-5-2-1-通用方法"><a href="#2-5-2-1-通用方法" class="headerlink" title="2.5.2.1 通用方法"></a>2.5.2.1 通用方法</h3><ul>
<li>所有scipy.sparse类都是spmatrix的子类<ul>
<li>算术操作的默认实现<ul>
<li>通常转化为CSR</li>
<li>为了效率而子类覆盖</li>
</ul>
</li>
<li>形状、数据类型设置/获取</li>
<li>非0索引</li>
<li>格式转化、与Numpy交互(toarray(), todense())</li>
<li>…</li>
</ul>
</li>
<li>属性:<ul>
<li>mtx.A - 与mtx.toarray()相同</li>
<li>mtx.T - 转置 (与mtx.transpose()相同)</li>
<li>mtx.H - Hermitian (列举) 转置</li>
<li>mtx.real - 复矩阵的真部</li>
<li>mtx.imag - 复矩阵的虚部</li>
<li>mtx.size - 非零数 (与self.getnnz()相同)</li>
<li>mtx.shape - 行数和列数 (元组)</li>
</ul>
</li>
<li>数据通常储存在Numpy数组中</li>
</ul>
<h3 id="2-5-2-2-稀疏矩阵类"><a href="#2-5-2-2-稀疏矩阵类" class="headerlink" title="2.5.2.2 稀疏矩阵类"></a>2.5.2.2 稀疏矩阵类</h3><h4 id="2-5-2-2-1-对角线格式-DIA"><a href="#2-5-2-2-1-对角线格式-DIA" class="headerlink" title="2.5.2.2.1 对角线格式 (DIA))"></a>2.5.2.2.1 对角线格式 (DIA))</h4><ul>
<li>非常简单的格式</li>
<li>形状 (n_diag, length) 的密集Numpy数组的对角线<ul>
<li>固定长度 -&gt; 当离主对角线比较远时会浪费空间</li>
<li>_data_matrix的子类 (带数据属性的稀疏矩阵类)</li>
</ul>
</li>
<li>每个对角线的偏移<ul>
<li>0 是主对角线</li>
<li>负偏移 = 下面</li>
<li>正偏移 = 上面</li>
</ul>
</li>
<li>快速矩阵 * 向量 (sparsetools)</li>
<li>快速方便的关于项目的操作<ul>
<li>直接操作数据数组 (快速的NumPy机件)</li>
</ul>
</li>
<li>构建器接受 :<ul>
<li>密集矩阵 (数组)</li>
<li>稀疏矩阵</li>
<li>形状元组 (创建空矩阵)</li>
<li>(数据, 偏移) 元组</li>
</ul>
</li>
<li>没有切片、没有单个项目访问</li>
<li>用法 :<ul>
<li>非常专业</li>
<li>通过有限微分解偏微分方程</li>
<li>有一个迭代求解器 ##### 2.5.2.2.1.1 示例</li>
</ul>
</li>
<li>创建一些DIA矩阵 :</li>
</ul>
<p>In [3]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data &#x3D; np.array([[1, 2, 3, 4]]).repeat(3, axis&#x3D;0)</span><br><span class="line">data</span><br></pre></td></tr></table></figure>
<p>Out[3]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[1, 2, 3, 4],</span><br><span class="line">       [1, 2, 3, 4],</span><br><span class="line">       [1, 2, 3, 4]])</span><br></pre></td></tr></table></figure>
<p>In [6]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">offsets &#x3D; np.array([0, -1, 2])</span><br><span class="line">mtx &#x3D; sparse.dia_matrix((data, offsets), shape&#x3D;(4, 4))</span><br><span class="line">mtx</span><br></pre></td></tr></table></figure>
<p>Out[6]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;4x4 sparse matrix of type &#39;&lt;type &#39;numpy.int64&#39;&gt;&#39;</span><br><span class="line">    with 9 stored elements (3 diagonals) in DIAgonal format&gt;</span><br></pre></td></tr></table></figure>
<p>In [7]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.todense()</span><br></pre></td></tr></table></figure>
<p>Out[7]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">matrix([[1, 0, 3, 0],</span><br><span class="line">        [1, 2, 0, 4],</span><br><span class="line">        [0, 2, 3, 0],</span><br><span class="line">        [0, 0, 3, 4]])</span><br></pre></td></tr></table></figure>
<p>In [9]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data &#x3D; np.arange(12).reshape((3, 4)) + 1</span><br><span class="line">data</span><br></pre></td></tr></table></figure>
<p>Out[9]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[ 1,  2,  3,  4],</span><br><span class="line">       [ 5,  6,  7,  8],</span><br><span class="line">       [ 9, 10, 11, 12]])</span><br></pre></td></tr></table></figure>
<p>In [10]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mtx &#x3D; sparse.dia_matrix((data, offsets), shape&#x3D;(4, 4))</span><br><span class="line">mtx.data</span><br></pre></td></tr></table></figure>
<p>Out[10]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[ 1,  2,  3,  4],</span><br><span class="line">       [ 5,  6,  7,  8],</span><br><span class="line">       [ 9, 10, 11, 12]])</span><br></pre></td></tr></table></figure>
<p>In [11]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.offsets</span><br></pre></td></tr></table></figure>
<p>Out[11]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([ 0, -1,  2], dtype&#x3D;int32)</span><br></pre></td></tr></table></figure>
<p>In [12]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">print mtx</span><br><span class="line">  (0, 0)    1</span><br><span class="line">  (1, 1)    2</span><br><span class="line">  (2, 2)    3</span><br><span class="line">  (3, 3)    4</span><br><span class="line">  (1, 0)    5</span><br><span class="line">  (2, 1)    6</span><br><span class="line">  (3, 2)    7</span><br><span class="line">  (0, 2)    11</span><br><span class="line">  (1, 3)    12</span><br></pre></td></tr></table></figure>
<p>In [13]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.todense()</span><br></pre></td></tr></table></figure>
<p>Out[13]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">matrix([[ 1,  0, 11,  0],</span><br><span class="line">        [ 5,  2,  0, 12],</span><br><span class="line">        [ 0,  6,  3,  0],</span><br><span class="line">        [ 0,  0,  7,  4]])</span><br></pre></td></tr></table></figure>
<ul>
<li>机制的解释 :</li>
</ul>
<p>偏移: 行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> 2:  9</span><br><span class="line"> 1:  --10------</span><br><span class="line"> 0:  1  . 11  .</span><br><span class="line">-1:  5  2  . 12</span><br><span class="line">-2:  .  6  3  .</span><br><span class="line">-3:  .  .  7  4</span><br><span class="line">     ---------8</span><br></pre></td></tr></table></figure>
<ul>
<li>矩阵-向量相乘</li>
</ul>
<p>In [15]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vec &#x3D; np.ones((4, ))</span><br><span class="line">vec</span><br></pre></td></tr></table></figure>
<p>Out[15]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([ 1.,  1.,  1.,  1.])</span><br></pre></td></tr></table></figure>
<p>In [16]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx * vec</span><br></pre></td></tr></table></figure>
<p>Out[16]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([ 12.,  19.,   9.,  11.])</span><br></pre></td></tr></table></figure>
<p>In [17]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.toarray() * vec</span><br></pre></td></tr></table></figure>
<p>Out[17]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">array([[  1.,   0.,  11.,   0.],</span><br><span class="line">       [  5.,   2.,   0.,  12.],</span><br><span class="line">       [  0.,   6.,   3.,   0.],</span><br><span class="line">       [  0.,   0.,   7.,   4.]])</span><br></pre></td></tr></table></figure>
<h4 id="2-5-2-2-2-列表的列表格式-LIL"><a href="#2-5-2-2-2-列表的列表格式-LIL" class="headerlink" title="2.5.2.2.2 列表的列表格式 (LIL))"></a>2.5.2.2.2 列表的列表格式 (LIL))</h4><ul>
<li>基于行的联接列表<ul>
<li>每一行是一个Python列表（排序的）非零元素的列索引</li>
<li>行存储在Numpy数组中 (dtype=np.object)</li>
<li>非零值也近似存储</li>
</ul>
</li>
<li>高效增量构建稀疏矩阵</li>
<li>构建器接受 :<ul>
<li>密集矩阵 (数组)</li>
<li>稀疏矩阵</li>
<li>形状元组 (创建一个空矩阵)</li>
</ul>
</li>
<li>灵活切片、高效改变稀疏结构</li>
<li>由于是基于行的，算术和行切片慢</li>
<li>用途 :<ul>
<li>当稀疏模式并不是已知的逻辑或改变</li>
<li>例子：从一个文本文件读取稀疏矩阵 ##### 2.5.2.2.2.1 示例</li>
</ul>
</li>
<li>创建一个空的LIL矩阵 :</li>
</ul>
<p>In [2]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx &#x3D; sparse.lil_matrix((4, 5))</span><br></pre></td></tr></table></figure>
<ul>
<li>准备随机数据:</li>
</ul>
<p>In [4]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from numpy.random import rand</span><br><span class="line">data &#x3D; np.round(rand(2, 3))</span><br><span class="line">data</span><br></pre></td></tr></table></figure>
<p>Out[4]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0.,  0.,  0.],</span><br><span class="line">       [ 1.,  0.,  0.]])</span><br></pre></td></tr></table></figure>
<ul>
<li>使用象征所以分配数据:</li>
</ul>
<p>In [6]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mtx[:2, [1, 2, 3]] &#x3D; data</span><br><span class="line">mtx</span><br></pre></td></tr></table></figure>
<p>Out[6]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;4x5 sparse matrix of type &#39;&lt;type &#39;numpy.float64&#39;&gt;&#39;</span><br><span class="line">    with 3 stored elements in LInked List format&gt;</span><br></pre></td></tr></table></figure>
<p>In [7]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print mtx</span><br><span class="line">  (0, 1)    1.0</span><br><span class="line">  (0, 3)    1.0</span><br><span class="line">  (1, 2)    1.0</span><br></pre></td></tr></table></figure>
<p>In [8]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.todense()</span><br></pre></td></tr></table></figure>
<p>Out[8]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">matrix([[ 0.,  1.,  0.,  1.,  0.],</span><br><span class="line">        [ 0.,  0.,  1.,  0.,  0.],</span><br><span class="line">        [ 0.,  0.,  0.,  0.,  0.],</span><br><span class="line">        [ 0.,  0.,  0.,  0.,  0.]])</span><br></pre></td></tr></table></figure>
<p>In [9]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.toarray()</span><br></pre></td></tr></table></figure>
<p>Out[9]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0.,  1.,  0.,  1.,  0.],</span><br><span class="line">       [ 0.,  0.,  1.,  0.,  0.],</span><br><span class="line">       [ 0.,  0.,  0.,  0.,  0.],</span><br><span class="line">       [ 0.,  0.,  0.,  0.,  0.]])</span><br></pre></td></tr></table></figure>
<p>更多的切片和索引:</p>
<p>In [10]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mtx &#x3D; sparse.lil_matrix([[0, 1, 2, 0], [3, 0, 1, 0], [1, 0, 0, 1]])</span><br><span class="line">mtx.todense()</span><br></pre></td></tr></table></figure>
<p>Out[10]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">matrix([[0, 1, 2, 0],</span><br><span class="line">        [3, 0, 1, 0],</span><br><span class="line">        [1, 0, 0, 1]])</span><br></pre></td></tr></table></figure>
<p>In [11]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print mtx</span><br><span class="line">  (0, 1)    1</span><br><span class="line">  (0, 2)    2</span><br><span class="line">  (1, 0)    3</span><br><span class="line">  (1, 2)    1</span><br><span class="line">  (2, 0)    1</span><br><span class="line">  (2, 3)    1</span><br></pre></td></tr></table></figure>
<p>In [12]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx[:2, :]</span><br></pre></td></tr></table></figure>
<p>Out[12]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;2x4 sparse matrix of type &#39;&lt;type &#39;numpy.int64&#39;&gt;&#39;</span><br><span class="line">    with 4 stored elements in LInked List format&gt;</span><br></pre></td></tr></table></figure>
<p>In [13]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx[:2, :].todense()</span><br></pre></td></tr></table></figure>
<p>Out[13]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">matrix([[0, 1, 2, 0],</span><br><span class="line">        [3, 0, 1, 0]])</span><br></pre></td></tr></table></figure>
<p>In [14]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx[1:2, [0,2]].todense()</span><br></pre></td></tr></table></figure>
<p>Out[14]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">matrix([[3, 1]])</span><br></pre></td></tr></table></figure>
<p>In [15]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.todense()</span><br></pre></td></tr></table></figure>
<p>Out[15]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">matrix([[0, 1, 2, 0],</span><br><span class="line">        [3, 0, 1, 0],</span><br><span class="line">        [1, 0, 0, 1]])</span><br></pre></td></tr></table></figure>
<h4 id="2-5-2-2-3-值的字典格式-DOK"><a href="#2-5-2-2-3-值的字典格式-DOK" class="headerlink" title="2.5.2.2.3 值的字典格式 (DOK))"></a>2.5.2.2.3 值的字典格式 (DOK))</h4><ul>
<li>Python字典的子类<ul>
<li>键是 (行, 列) 索引元组 (不允许重复的条目)</li>
<li>值是对应的非零值</li>
</ul>
</li>
<li>高效增量构建稀疏矩阵</li>
<li>构建器支持:<ul>
<li>密集矩阵 (数组)</li>
<li>稀疏矩阵</li>
<li>形状元组 (创建空矩阵)</li>
</ul>
</li>
<li>高效 O(1) 对单个元素的访问</li>
<li>灵活索引，改变稀疏结构是高效</li>
<li>一旦创建完成后可以被高效转换为coo_matrix</li>
<li>算术很慢 (循环用<code>dict.iteritems()</code>)</li>
<li>用法:<ul>
<li>当稀疏模式是未知的假设或改变时</li>
</ul>
</li>
</ul>
<h5 id="2-5-2-2-3-1-示例"><a href="#2-5-2-2-3-1-示例" class="headerlink" title="2.5.2.2.3.1 示例"></a>2.5.2.2.3.1 示例</h5><ul>
<li>逐个元素创建一个DOK矩阵:</li>
</ul>
<p>In [16]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mtx &#x3D; sparse.dok_matrix((5, 5), dtype&#x3D;np.float64)</span><br><span class="line">mtx</span><br></pre></td></tr></table></figure>
<p>Out[16]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;5x5 sparse matrix of type &#39;&lt;type &#39;numpy.float64&#39;&gt;&#39;</span><br><span class="line">    with 0 stored elements in Dictionary Of Keys format&gt;</span><br></pre></td></tr></table></figure>
<p>In [17]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for ir in range(5):</span><br><span class="line">    for ic in range(5):</span><br><span class="line">        mtx[ir, ic] &#x3D; 1.0 * (ir !&#x3D; ic)</span><br><span class="line">mtx</span><br></pre></td></tr></table></figure>
<p>Out[17]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;5x5 sparse matrix of type &#39;&lt;type &#39;numpy.float64&#39;&gt;&#39;</span><br><span class="line">    with 20 stored elements in Dictionary Of Keys format&gt;</span><br></pre></td></tr></table></figure>
<p>In [18]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.todense()</span><br></pre></td></tr></table></figure>
<p>Out[18]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">matrix([[ 0.,  1.,  1.,  1.,  1.],</span><br><span class="line">        [ 1.,  0.,  1.,  1.,  1.],</span><br><span class="line">        [ 1.,  1.,  0.,  1.,  1.],</span><br><span class="line">        [ 1.,  1.,  1.,  0.,  1.],</span><br><span class="line">        [ 1.,  1.,  1.,  1.,  0.]])</span><br></pre></td></tr></table></figure>
<ul>
<li>切片与索引:</li>
</ul>
<p>In [19]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx[1, 1]</span><br></pre></td></tr></table></figure>
<p>Out[19]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.0</span><br></pre></td></tr></table></figure>
<p>In [20]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx[1, 1:3]</span><br></pre></td></tr></table></figure>
<p>Out[20]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;1x2 sparse matrix of type &#39;&lt;type &#39;numpy.float64&#39;&gt;&#39;</span><br><span class="line">    with 1 stored elements in Dictionary Of Keys format&gt;</span><br></pre></td></tr></table></figure>
<p>In [21]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx[1, 1:3].todense()</span><br></pre></td></tr></table></figure>
<p>Out[21]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">matrix([[ 0.,  1.]])</span><br></pre></td></tr></table></figure>
<p>In [22]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx[[2,1], 1:3].todense()</span><br></pre></td></tr></table></figure>
<p>Out[22]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">matrix([[ 1.,  0.],</span><br><span class="line">        [ 0.,  1.]])</span><br></pre></td></tr></table></figure>
<h4 id="2-5-2-2-4-座标格式-COO"><a href="#2-5-2-2-4-座标格式-COO" class="headerlink" title="2.5.2.2.4 座标格式 (COO))"></a>2.5.2.2.4 座标格式 (COO))</h4><ul>
<li>也被称为 ‘ijv’ 或 ‘triplet’ 格式<ul>
<li>三个NumPy数组: row, col, data</li>
<li><code>data[i]</code>是在 (row[i], col[i]) 位置的值</li>
<li>允许重复值</li>
</ul>
</li>
<li><code>\_data\_matrix</code>的子类 (带有<code>data</code>属性的稀疏矩阵类)</li>
<li>构建稀疏矩阵的高速模式</li>
<li>构建器接受:<ul>
<li>密集矩阵 (数组)</li>
<li>稀疏矩阵</li>
<li>形状元组 (创建空数组)</li>
<li><code>(data, ij)</code>元组</li>
</ul>
</li>
<li>与CSR/CSC格式非常快的互相转换</li>
<li>快速的矩阵 * 向量 (sparsetools)</li>
<li>快速而简便的逐项操作<ul>
<li>直接操作数据数组 (快速NumPy机制)</li>
</ul>
</li>
<li>没有切片，没有算术 (直接)</li>
<li>使用:<ul>
<li>在各种稀疏格式间的灵活转换</li>
<li>当转化到其他形式 (通常是 CSR 或 CSC), 重复的条目被加总到一起<ul>
<li>有限元素矩阵的快速高效创建</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="2-5-2-2-4-1-示例"><a href="#2-5-2-2-4-1-示例" class="headerlink" title="2.5.2.2.4.1 示例"></a>2.5.2.2.4.1 示例</h5><ul>
<li>创建空的COO矩阵:</li>
</ul>
<p>In [23]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mtx &#x3D; sparse.coo_matrix((3, 4), dtype&#x3D;np.int8)</span><br><span class="line">mtx.todense()</span><br></pre></td></tr></table></figure>
<p>Out[23]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">matrix([[0, 0, 0, 0],</span><br><span class="line">        [0, 0, 0, 0],</span><br><span class="line">        [0, 0, 0, 0]], dtype&#x3D;int8)</span><br></pre></td></tr></table></figure>
<ul>
<li>用 (data, ij) 元组创建:</li>
</ul>
<p>In [24]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">row &#x3D; np.array([0, 3, 1, 0])</span><br><span class="line">col &#x3D; np.array([0, 3, 1, 2])</span><br><span class="line">data &#x3D; np.array([4, 5, 7, 9])</span><br><span class="line">mtx &#x3D; sparse.coo_matrix((data, (row, col)), shape&#x3D;(4, 4))</span><br><span class="line">mtx</span><br></pre></td></tr></table></figure>
<p>Out[24]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;4x4 sparse matrix of type &#39;&lt;type &#39;numpy.int64&#39;&gt;&#39;</span><br><span class="line">    with 4 stored elements in COOrdinate format&gt;</span><br></pre></td></tr></table></figure>
<p>In [25]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.todense()</span><br></pre></td></tr></table></figure>
<p>Out[25]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">matrix([[4, 0, 9, 0],</span><br><span class="line">        [0, 7, 0, 0],</span><br><span class="line">        [0, 0, 0, 0],</span><br><span class="line">        [0, 0, 0, 5]])</span><br></pre></td></tr></table></figure>
<h4 id="2-5-2-2-5-压缩稀疏行格式-CSR"><a href="#2-5-2-2-5-压缩稀疏行格式-CSR" class="headerlink" title="2.5.2.2.5 压缩稀疏行格式 (CSR))"></a>2.5.2.2.5 压缩稀疏行格式 (CSR))</h4><ul>
<li><p>面向行</p>
<ul>
<li>三个Numpy数组:</li>
</ul>
</li>
</ul>
<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">indices</span><br></pre></td></tr></table></figure>

,



<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">indptr</span><br></pre></td></tr></table></figure>

,



<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data</span><br></pre></td></tr></table></figure>

- `indices`是列索引的数组
- `data`是对应的非零值数组
- `indptr`指向行开始的所以和数据
- 长度是`n_row + 1`, 最后一个项目 = 值数量 = `indices`和`data`的长度
- i-th行的非零值是列索引为`indices[indptr[i]:indptr[i+1]]`的`data[indptr[i]:indptr[i+1]]`
- 项目 (i, j) 可以通过`data[indptr[i]+k]`, k是j在`indices[indptr[i]:indptr[i+1]]`的位置来访问
</code></pre><ul>
<li><p><code>_cs_matrix</code> (常规 CSR/CSC 功能) 的子类</p>
</li>
<li><p><code>_data_matrix</code> (带有<code>data</code>属性的稀疏矩阵类) 的子类</p>
</li>
</ul>
<ul>
<li><p>快速矩阵向量相乘和其他算术 (sparsetools)</p>
</li>
<li><p>构建器接受:</p>
<ul>
<li>密集矩阵 (数组)</li>
<li>稀疏矩阵</li>
<li>形状元组 (创建空矩阵)</li>
<li><code>(data, ij)</code> 元组</li>
<li><code>(data, indices, indptr)</code> 元组</li>
</ul>
</li>
<li><p>高效行切片，面向行的操作</p>
</li>
<li><p>较慢的列切片，改变稀疏结构代价昂贵</p>
</li>
<li><p>用途:</p>
<ul>
<li>实际计算 (大多数线性求解器都支持这个格式)</li>
</ul>
</li>
</ul>
<h5 id="2-5-2-2-5-1-示例"><a href="#2-5-2-2-5-1-示例" class="headerlink" title="2.5.2.2.5.1 示例"></a>2.5.2.2.5.1 示例</h5><ul>
<li>创建空的CSR矩阵:</li>
</ul>
<p>In [26]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mtx &#x3D; sparse.csr_matrix((3, 4), dtype&#x3D;np.int8)</span><br><span class="line">mtx.todense()</span><br></pre></td></tr></table></figure>
<p>Out[26]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">matrix([[0, 0, 0, 0],</span><br><span class="line">        [0, 0, 0, 0],</span><br><span class="line">        [0, 0, 0, 0]], dtype&#x3D;int8)</span><br></pre></td></tr></table></figure>
<ul>
<li>用<code>(data, ij)</code>元组创建:</li>
</ul>
<p>In [27]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">row &#x3D; np.array([0, 0, 1, 2, 2, 2])</span><br><span class="line">col &#x3D; np.array([0, 2, 2, 0, 1, 2])</span><br><span class="line">data &#x3D; np.array([1, 2, 3, 4, 5, 6])</span><br><span class="line">mtx &#x3D; sparse.csr_matrix((data, (row, col)), shape&#x3D;(3, 3))</span><br><span class="line">mtx</span><br></pre></td></tr></table></figure>
<p>Out[27]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;3x3 sparse matrix of type &#39;&lt;type &#39;numpy.int64&#39;&gt;&#39;</span><br><span class="line">    with 6 stored elements in Compressed Sparse Row format&gt;</span><br></pre></td></tr></table></figure>
<p>In [28]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.todense()</span><br></pre></td></tr></table></figure>
<p>Out[28]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">matrix([[1, 0, 2],</span><br><span class="line">        [0, 0, 3],</span><br><span class="line">        [4, 5, 6]])</span><br></pre></td></tr></table></figure>
<p>In [29]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.data</span><br></pre></td></tr></table></figure>
<p>Out[29]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([1, 2, 3, 4, 5, 6])</span><br></pre></td></tr></table></figure>
<p>In [30]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.indices</span><br></pre></td></tr></table></figure>
<p>Out[30]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([0, 2, 2, 0, 1, 2], dtype&#x3D;int32)</span><br></pre></td></tr></table></figure>
<p>In [31]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mtx.indptr</span><br></pre></td></tr></table></figure>
<p>Out[31]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([0, 2, 3, 6], dtype&#x3D;int32)</span><br></pre></td></tr></table></figure>
<p>用<code>(data, indices, indptr)</code>元组创建:</p>
<p>In [32]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data &#x3D; np.array([1, 2, 3, 4, 5, 6])</span><br><span class="line">indices &#x3D; np.array([0, 2, 2, 0, 1, 2])</span><br><span class="line">indptr &#x3D; np.array([0, 2, 3, 6])</span><br><span class="line">mtx &#x3D; sparse.csr_matrix((data, indices, indptr), shape&#x3D;(3, 3))</span><br><span class="line">mtx.todense()</span><br></pre></td></tr></table></figure>
<p>Out[32]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">matrix([[1, 0, 2],</span><br><span class="line">        [0, 0, 3],</span><br><span class="line">        [4, 5, 6]])</span><br></pre></td></tr></table></figure>
<h4 id="2-5-2-2-6-压缩稀疏列格式-CSC"><a href="#2-5-2-2-6-压缩稀疏列格式-CSC" class="headerlink" title="2.5.2.2.6 压缩稀疏列格式 (CSC))"></a>2.5.2.2.6 压缩稀疏列格式 (CSC))</h4><ul>
<li><p>面向列</p>
<ul>
<li><p>三个Numpy数组: <code>indices</code>、<code>indptr</code>、<code>data</code></p>
</li>
<li><p><code>indices</code>是行索引的数组</p>
</li>
<li><p><code>data</code>是对应的非零值</p>
</li>
<li><p><code>indptr</code>指向<code>indices</code>和<code>data</code>开始的列</p>
</li>
<li><p>长度是<code>n_col + 1</code>, 最后一个条目 = 值数量 = <code>indices</code>和<code>data</code>的长度</p>
</li>
<li><p>第i列的非零值是行索引为<code>indices[indptr[i]:indptr[i+1]]</code>的<code>data[indptr[i]:indptr[i+1]]</code></p>
</li>
<li><p>项目 (i, j) 可以作为<code>data[indptr[j]+k]</code>访问, k是i在<code>indices[indptr[j]:indptr[j+1]]</code>的位置</p>
</li>
<li><p>```<br>_cs_matrix</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    的子类 (通用的 CSR&#x2F;CSC 功能性)</span><br><span class="line"></span><br><span class="line">    - &#96;_data_matrix&#96;的子类 (带有&#96;data&#96;属性的稀疏矩阵类)</span><br><span class="line"></span><br><span class="line">- 快速的矩阵和向量相乘及其他数学 (sparsetools)</span><br><span class="line"></span><br><span class="line">- 构建器接受：</span><br><span class="line"></span><br><span class="line">  - 密集矩阵 (数组)</span><br><span class="line">  - 稀疏矩阵</span><br><span class="line">  - 形状元组 (创建空矩阵)</span><br><span class="line">  - &#96;(data, ij)&#96;元组</span><br><span class="line">  - &#96;(data, indices, indptr)&#96;元组</span><br><span class="line"></span><br><span class="line">- 高效列切片、面向列的操作</span><br><span class="line"></span><br><span class="line">- 较慢的行切片、改变稀疏结构代价昂贵</span><br><span class="line"></span><br><span class="line">- 用途:</span><br><span class="line"></span><br><span class="line">  - 实际计算 (巨大多数线性求解器支持这个格式)</span><br><span class="line"></span><br><span class="line">##### 2.5.2.2.6.1 示例</span><br><span class="line"></span><br><span class="line">- 创建空CSC矩阵:</span><br><span class="line"></span><br><span class="line">In [33]:</span><br></pre></td></tr></table></figure>
<p>mtx = sparse.csc_matrix((3, 4), dtype=np.int8)<br>mtx.todense()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[33]:</span><br></pre></td></tr></table></figure>
<p>matrix([[0, 0, 0, 0],</p>
<pre><code>[0, 0, 0, 0],
[0, 0, 0, 0]], dtype=int8)
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 用&#96;(data, ij)&#96;元组创建:</span><br><span class="line"></span><br><span class="line">In [34]:</span><br></pre></td></tr></table></figure>
<p>row = np.array([0, 0, 1, 2, 2, 2])<br>col = np.array([0, 2, 2, 0, 1, 2])<br>data = np.array([1, 2, 3, 4, 5, 6])<br>mtx = sparse.csc_matrix((data, (row, col)), shape=(3, 3))<br>mtx</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[34]:</span><br></pre></td></tr></table></figure>
<p><3x3 sparse matrix of type '<type 'numpy.int64'>'
with 6 stored elements in Compressed Sparse Column format></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [35]:</span><br></pre></td></tr></table></figure>
<p>mtx.todense()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[35]:</span><br></pre></td></tr></table></figure>
<p>matrix([[1, 0, 2],</p>
<pre><code>[0, 0, 3],
[4, 5, 6]])
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [36]:</span><br></pre></td></tr></table></figure>
<p>mtx.data</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[36]:</span><br></pre></td></tr></table></figure>
<p>array([1, 4, 5, 2, 3, 6])</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [37]:</span><br></pre></td></tr></table></figure>
<p>mtx.indices</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[37]:</span><br></pre></td></tr></table></figure>
<p>array([0, 2, 2, 0, 1, 2], dtype=int32)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [38]:</span><br></pre></td></tr></table></figure>
<p>mtx.indptr</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[38]:</span><br></pre></td></tr></table></figure>
<p>array([0, 2, 3, 6], dtype=int32)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 用&#96;(data, indices, indptr)&#96;元组创建:</span><br><span class="line"></span><br><span class="line">In [39]:</span><br></pre></td></tr></table></figure>
<p>data = np.array([1, 4, 5, 2, 3, 6])<br>indices = np.array([0, 2, 2, 0, 1, 2])<br>indptr = np.array([0, 2, 3, 6])<br>mtx = sparse.csc_matrix((data, indices, indptr), shape=(3, 3))<br>mtx.todense()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[39]:</span><br></pre></td></tr></table></figure>
<p>matrix([[1, 0, 2],</p>
<pre><code>[0, 0, 3],
[4, 5, 6]])
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### 2.5.2.2.7 块压缩行格式 (BSR))</span><br><span class="line"></span><br><span class="line">- 本质上，CSR带有密集的固定形状的子矩阵而不是纯量的项目</span><br><span class="line"></span><br><span class="line">  - 块大小&#96;(R, C)&#96;必须可以整除矩阵的形状&#96;(M, N)&#96;</span><br><span class="line"></span><br><span class="line">  - 三个Numpy数组:</span><br></pre></td></tr></table></figure>
<p>indices</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">、</span><br></pre></td></tr></table></figure>
<p>indptr</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">、</span><br></pre></td></tr></table></figure>
<p>data</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    - &#96;indices&#96;是每个块列索引的数组</span><br><span class="line">    - &#96;data&#96;是形状为(nnz, R, C)对应的非零值</span><br><span class="line">    - ...</span><br><span class="line"></span><br><span class="line">  - &#96;_cs_matrix&#96;的子类 (通用的CSR&#x2F;CSC功能性)</span><br><span class="line"></span><br><span class="line">  - &#96;_data_matrix&#96;的子类 (带有&#96;data&#96;属性的稀疏矩阵类)</span><br><span class="line"></span><br><span class="line">- 快速矩阵向量相乘和其他的算术 (sparsetools)</span><br><span class="line"></span><br><span class="line">- 构建器接受:</span><br><span class="line"></span><br><span class="line">  - 密集矩阵 (数组)</span><br><span class="line">  - 稀疏矩阵</span><br><span class="line">  - 形状元组 (创建空的矩阵)</span><br><span class="line">  - &#96;(data, ij)&#96;元组</span><br><span class="line">  - &#96;(data, indices, indptr)&#96;元组</span><br><span class="line"></span><br><span class="line">- 许多对于带有密集子矩阵的稀疏矩阵算术操作比CSR更高效很多</span><br><span class="line"></span><br><span class="line">- 用途:</span><br><span class="line"></span><br><span class="line">  - 类似CSR</span><br><span class="line">  - 有限元素向量值离散化 ##### 2.5.2.2.7.1 示例</span><br><span class="line"></span><br><span class="line">- 创建空的&#96;(1, 1)&#96;块大小的（类似CSR...）的BSR矩阵:</span><br><span class="line"></span><br><span class="line">In [40]:</span><br></pre></td></tr></table></figure>
<p>mtx = sparse.bsr_matrix((3, 4), dtype=np.int8)<br>mtx</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[40]:</span><br></pre></td></tr></table></figure>
<p><3x4 sparse matrix of type '<type 'numpy.int8'>'
with 0 stored elements (blocksize = 1x1) in Block Sparse Row format></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [41]:</span><br></pre></td></tr></table></figure>
<p>mtx.todense()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[41]:</span><br></pre></td></tr></table></figure>
<p>matrix([[0, 0, 0, 0],</p>
<pre><code>[0, 0, 0, 0],
[0, 0, 0, 0]], dtype=int8)
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 创建块大小&#96;(3, 2)&#96;的空BSR矩阵:</span><br><span class="line"></span><br><span class="line">In [42]:</span><br></pre></td></tr></table></figure>
<p>mtx = sparse.bsr_matrix((3, 4), blocksize=(3, 2), dtype=np.int8)<br>mtx</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[42]:</span><br></pre></td></tr></table></figure>
<3x4 sparse matrix of type '<type 'numpy.int8'>'
with 0 stored elements (blocksize = 3x2) in Block Sparse Row format></li>
</ul>
</li>
<li><p>一个bug?</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 用&#96;(1, 1)&#96;块大小 (类似 CSR...)&#96;(data, ij)&#96;的元组创建:</span><br><span class="line"></span><br><span class="line">In [43]:</span><br></pre></td></tr></table></figure>
<p>row = np.array([0, 0, 1, 2, 2, 2])<br>col = np.array([0, 2, 2, 0, 1, 2])<br>data = np.array([1, 2, 3, 4, 5, 6])<br>mtx = sparse.bsr_matrix((data, (row, col)), shape=(3, 3))<br>mtx</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[43]:</span><br></pre></td></tr></table></figure>
<p><3x3 sparse matrix of type '<type 'numpy.int64'>'
  with 6 stored elements (blocksize = 1x1) in Block Sparse Row format></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [44]:</span><br></pre></td></tr></table></figure>
<p>mtx.todense()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[44]:</span><br></pre></td></tr></table></figure>
<p>matrix([[1, 0, 2],</p>
<pre><code>  [0, 0, 3],
  [4, 5, 6]])
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [45]:</span><br></pre></td></tr></table></figure>
<p>mtx.indices</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[45]:</span><br></pre></td></tr></table></figure>
<p>array([0, 2, 2, 0, 1, 2], dtype=int32)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [46]:</span><br></pre></td></tr></table></figure>
<p>mtx.indptr</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[46]:</span><br></pre></td></tr></table></figure>
<p>array([0, 2, 3, 6], dtype=int32)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 用&#96;(2, 1)&#96;块大小&#96;(data, indices, indptr)&#96;的元组创建:</span><br><span class="line"></span><br><span class="line">In [47]:</span><br></pre></td></tr></table></figure>
<p>indptr = np.array([0, 2, 3, 6])<br>indices = np.array([0, 2, 2, 0, 1, 2])<br>data = np.array([1, 2, 3, 4, 5, 6]).repeat(4).reshape(6, 2, 2)<br>mtx = sparse.bsr_matrix((data, indices, indptr), shape=(6, 6))<br>mtx.todense()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[47]:</span><br></pre></td></tr></table></figure>
<p>matrix([[1, 1, 0, 0, 2, 2],</p>
<pre><code>  [1, 1, 0, 0, 2, 2],
  [0, 0, 0, 0, 3, 3],
  [0, 0, 0, 0, 3, 3],
  [4, 4, 5, 5, 6, 6],
  [4, 4, 5, 5, 6, 6]])
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [48]:</span><br></pre></td></tr></table></figure>
<p>data</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Out[48]:</span><br></pre></td></tr></table></figure>
<p>array([[[1, 1],</p>
<pre><code>  [1, 1]],

 [[2, 2],
  [2, 2]],

 [[3, 3],
  [3, 3]],

 [[4, 4],
  [4, 4]],

 [[5, 5],
  [5, 5]],

 [[6, 6],
  [6, 6]]])
</code></pre><p>```</p>
</li>
</ul>
<h3 id="2-5-2-3-总结"><a href="#2-5-2-3-总结" class="headerlink" title="2.5.2.3 总结"></a>2.5.2.3 总结</h3><p>存储机制的总结</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>格式</th>
<th>矩阵 * 向量</th>
<th>提取项目</th>
<th>灵活提取</th>
<th>设置项目</th>
<th>灵活设置</th>
<th>求解器</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>DIA</td>
<td>sparsetools</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>迭代</td>
<td>有数据数组，专门化</td>
</tr>
<tr>
<td>LIL</td>
<td>通过 CSR</td>
<td>是</td>
<td>是</td>
<td>是</td>
<td>是</td>
<td>迭代</td>
<td>通过CSR的算术, 增量构建</td>
</tr>
<tr>
<td>DOK</td>
<td>python</td>
<td>是</td>
<td>只有一个轴</td>
<td>是</td>
<td>是</td>
<td>迭代</td>
<td><code>O(1)</code>条目访问, 增量构建</td>
</tr>
<tr>
<td>COO</td>
<td>sparsetools</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>迭代</td>
<td>有数据数组, 便利的快速转换</td>
</tr>
<tr>
<td>CSR</td>
<td>sparsetools</td>
<td>是</td>
<td>是</td>
<td>慢</td>
<td>.</td>
<td>任何</td>
<td>有数据数组, 快速以行为主的操作</td>
</tr>
<tr>
<td>CSC</td>
<td>sparsetools</td>
<td>是</td>
<td>是</td>
<td>慢</td>
<td>.</td>
<td>任何</td>
<td>有数据数组, 快速以列为主的操作</td>
</tr>
<tr>
<td>BSR</td>
<td>sparsetools</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>专门化</td>
<td>有数据数组，专门化</td>
</tr>
</tbody>
</table>
</div>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/04/2020-3-3-skearn_learning-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LelandYan">
      <meta itemprop="description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LelandYan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/04/2020-3-3-skearn_learning-2020/" class="post-title-link" itemprop="url">sklearn的非数值进行数值性编码与sklearn的库进行准确率的计算</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-04 12:08:25 / 修改时间：14:24:57" itemprop="dateCreated datePublished" datetime="2020-03-04T12:08:25+08:00">2020-03-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hey"><a href="#Hey" class="headerlink" title="Hey"></a>Hey</h1><blockquote>
<p>Machine Learning notes</p>
</blockquote>
<h1 id="skearn的非数值进行数值性编码与sklearn的库进行准确率的计算"><a href="#skearn的非数值进行数值性编码与sklearn的库进行准确率的计算" class="headerlink" title="skearn的非数值进行数值性编码与sklearn的库进行准确率的计算"></a>skearn的非数值进行数值性编码与sklearn的库进行准确率的计算</h1><p>1.可以使用python自带的skearn对result的非数值进行数值性编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">y = LabelEncoder().fit_transform(data[<span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<p>2.可以使用sklearn的库进行准确率的计算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_socre</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=<span class="number">0.7</span>, random_state=<span class="number">1</span>)</span><br><span class="line">model = DecisionTreeClassifier(criterion=<span class="string">'entorpy'</span>)</span><br><span class="line">model.fit(x_train,y_train)</span><br><span class="line">y_test_hat = model.predict(x_test)</span><br><span class="line"><span class="comment"># 第一种方法</span></span><br><span class="line">print(<span class="string">"accuracy_score"</span>,accuracy_socre(y_test_hat,y_test))</span><br><span class="line"><span class="comment"># 第二种方法</span></span><br><span class="line">y_test = y_test.reshape(<span class="number">-1</span>)<span class="comment"># 变成一维</span></span><br><span class="line">result = (y_test_hat==y_test)</span><br><span class="line">acc = np.mean(result)</span><br><span class="line">print(<span class="string">f"准确率:<span class="subst">&#123;<span class="number">100</span>*acc&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/04/2020-3-3-sklearn_feature_engineer-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LelandYan">
      <meta itemprop="description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LelandYan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/04/2020-3-3-sklearn_feature_engineer-2020/" class="post-title-link" itemprop="url">sklearn中的数据预处理代码</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-04 12:08:25 / 修改时间：14:26:01" itemprop="dateCreated datePublished" datetime="2020-03-04T12:08:25+08:00">2020-03-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hey"><a href="#Hey" class="headerlink" title="Hey"></a>Hey</h1><blockquote>
<p>Machine Learning notes</p>
</blockquote>
<h1 id="sklearn中的数据预处理代码"><a href="#sklearn中的数据预处理代码" class="headerlink" title="sklearn中的数据预处理代码"></a>sklearn中的数据预处理代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">StandardScaler.fit_transform(iris.data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 区间放缩法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line">MinMaxScaler.fit_transform(iris.data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Normalizer</span><br><span class="line"><span class="comment">#归一化，返回值为归一化后的数据</span></span><br><span class="line">Normalizer().fit_transform(iris.data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对特定的特征二值化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Binarizer</span><br><span class="line"><span class="comment"># 二值化，阀值设为3，返回二值化后的数据</span></span><br><span class="line">Binarizer(threshold=<span class="number">3</span>).fit_transform(iris.data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对定性特征哑编码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="comment">#哑编码，对IRIS数据集的目标值，返回值为哑编码后的数据</span></span><br><span class="line">OneHotEncoder().fit_transform(iris.target.reshape((<span class="number">-1</span>,<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 缺失值计算</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> vstack, array, nan</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"><span class="comment">#缺失值计算，返回值为计算缺失值后的数据</span></span><br><span class="line"><span class="comment">#参数missing_value为缺失值的表示形式，默认为NaN</span></span><br><span class="line"><span class="comment">#参数strategy为缺失值填充方式，默认为mean（均值）</span></span><br><span class="line">Imputer().fit_transform(vstack((array([nan, nan, nan, nan]), iris.data)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据变化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="comment">#多项式转换</span></span><br><span class="line"><span class="comment">#参数degree为度，默认值为2</span></span><br><span class="line">PolynomialFeatures().fit_transform(iris.data)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> log1p</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> FunctionTransformer</span><br><span class="line"><span class="comment">#自定义转换函数为对数函数的数据变换</span></span><br><span class="line"><span class="comment">#第一个参数是单变元函数</span></span><br><span class="line">FunctionTransformer(log1p).fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>类</th>
<th>功能</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>StandardScaler</td>
<td>无量纲化</td>
<td>标准化，基于特征矩阵的列，将特征值转换至服从标准正态分布</td>
</tr>
<tr>
<td>MinMaxScaler</td>
<td>无量纲化</td>
<td>区间缩放，基于最大最小值，将特征值转换到[0, 1]区间上</td>
</tr>
<tr>
<td>Normalizer</td>
<td>归一化</td>
<td>基于特征矩阵的行，将样本向量转换为“单位向量”</td>
</tr>
<tr>
<td>Binarizer</td>
<td>二值化</td>
<td>基于给定阈值，将定量特征按阈值划分</td>
</tr>
<tr>
<td>OneHotEncoder</td>
<td>哑编码</td>
<td>将定性数据编码为定量数据</td>
</tr>
<tr>
<td>Imputer</td>
<td>缺失值计算</td>
<td>计算缺失值，缺失值可填充为均值等</td>
</tr>
<tr>
<td>PolynomialFeatures</td>
<td>多项式数据转换</td>
<td>多项式数据转换</td>
</tr>
<tr>
<td>FunctionTransformer</td>
<td>自定义单元数据转换</td>
<td>使用单变元的函数来转换数据</td>
</tr>
</tbody>
</table>
</div>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><p>　　当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征：</p>
<ul>
<li>特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。</li>
<li>特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择。除方差法外，本文介绍的其他方法均从相关性考虑。</li>
</ul>
<p>　　根据特征选择的形式又可以将特征选择方法分为3种：</p>
<ul>
<li>Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。</li>
<li>Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。</li>
<li>Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># filter ########################################################################################</span></span><br><span class="line"><span class="comment"># 方差选择法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceTreshold</span><br><span class="line"><span class="comment"># 方差选择法，返回值为特征选择后的数据</span></span><br><span class="line"><span class="comment"># 参数为threshold为方差的阀值</span></span><br><span class="line">VarianceThreshold(threshold=<span class="number">3</span>).fit_transform(iris.data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 相关系数法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="comment">#选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line"><span class="comment">#第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。在此定义为计算相关系数</span></span><br><span class="line"><span class="comment">#参数k为选择的特征个数</span></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(map(<span class="keyword">lambda</span> x:pearsonr(x, Y), X.T)).T, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># 卡方分布</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2 </span><br><span class="line"><span class="comment">#选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line">SelectKBest(chi2, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 互信息法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> minepy <span class="keyword">import</span> MINE</span><br><span class="line"></span><br><span class="line"><span class="comment">#由于MINE的设计不是函数式的，定义mic方法将其为函数式的，返回一个二元组，二元组的第2项设置成固定的P值0.5</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mic</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    m = MINE()</span><br><span class="line">    m.compute_score(x, y)</span><br><span class="line">    <span class="keyword">return</span> (m.mic(), <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择K个最好的特征，返回特征选择后的数据</span></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(map(<span class="keyword">lambda</span> x:mic(x, Y), X.T)).T, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># wrapper######################################################################################</span></span><br><span class="line"><span class="comment">#递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮#训练</span></span><br><span class="line"><span class="comment"># 递归特征消除法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment">#递归特征消除法，返回特征选择后的数据</span></span><br><span class="line"><span class="comment">#参数estimator为基模型</span></span><br><span class="line"><span class="comment">#参数n_features_to_select为选择的特征个数</span></span><br><span class="line">RFE(estimator=LogisticRegression(), n_features_to_select=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># embedded #################################################################################3####</span></span><br><span class="line"><span class="comment"># 使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维。</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression </span><br><span class="line"><span class="comment">#带L1惩罚项的逻辑回归作为基模型的特征选择</span></span><br><span class="line">SelectFromModel(LogisticRegression(penalty=<span class="string">"l1"</span>, C=<span class="number">0.1</span>)).fit_transform(iris.data, iris.target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基于树模型的特征选择法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment">#GBDT作为基模型的特征选择</span></span><br><span class="line">SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>类</th>
<th>所属方式</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>VarianceThreshold</td>
<td>Filter</td>
<td>方差选择法</td>
</tr>
<tr>
<td>SelectKBest</td>
<td>Filter</td>
<td>可选关联系数、卡方校验、最大信息系数作为得分计算的方法</td>
</tr>
<tr>
<td>RFE</td>
<td>Wrapper</td>
<td>递归地训练基模型，将权值系数较小的特征从特征集合中消除</td>
</tr>
<tr>
<td>SelectFromModel</td>
<td>Embedded</td>
<td>训练基模型，选择权值系数较高的特征</td>
</tr>
</tbody>
</table>
</div>
<h2 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h2><p>当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的。常见的降维方法除了以上提到的基于L1惩罚项的模型以外，另外还有主成分分析法（PCA）和线性判别分析（LDA），线性判别分析本身也是一个分类模型。PCA和LDA有很多的相似点，其本质是要将原始的样本映射到维度更低的样本空间中，但是PCA和LDA的映射目标不一样：<a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/08/lda-and-pca-machine-learning.html" target="_blank" rel="noopener">PCA是为了让映射后的样本具有最大的发散性；而LDA是为了让映射后的样本有最好的分类性能</a>。所以说PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。</p>
<h2 id="4-1-主成分分析法（PCA）"><a href="#4-1-主成分分析法（PCA）" class="headerlink" title="4.1 主成分分析法（PCA）"></a>4.1 主成分分析法（PCA）</h2><p>　　使用decomposition库的PCA类选择特征的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1 from sklearn.decomposition import PCA</span><br><span class="line">2 </span><br><span class="line">3 #主成分分析法，返回降维后的数据</span><br><span class="line">4 #参数n_components为主成分数目</span><br><span class="line">5 PCA(n_components&#x3D;2).fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<h2 id="4-2-线性判别分析法（LDA）"><a href="#4-2-线性判别分析法（LDA）" class="headerlink" title="4.2 线性判别分析法（LDA）"></a>4.2 线性判别分析法（LDA）</h2><p>　　使用lda库的LDA类选择特征的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1 from sklearn.lda import LDA</span><br><span class="line">2 </span><br><span class="line">3 #线性判别分析法，返回降维后的数据</span><br><span class="line">4 #参数n_components为降维后的维数</span><br><span class="line">5 LDA(n_components&#x3D;2).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<h2 id="4-3-回顾"><a href="#4-3-回顾" class="headerlink" title="4.3 回顾"></a>4.3 回顾</h2><div class="table-container">
<table>
<thead>
<tr>
<th>库</th>
<th>类</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>decomposition</td>
<td>PCA</td>
<td>主成分分析法</td>
</tr>
<tr>
<td>lda</td>
<td>LDA</td>
<td>线性判别分析法</td>
</tr>
</tbody>
</table>
</div>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/04/2020-3-3-softmax_function-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LelandYan">
      <meta itemprop="description" content="涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LelandYan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/04/2020-3-3-softmax_function-2020/" class="post-title-link" itemprop="url">softmaxa Regression</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-04 12:08:25 / 修改时间：14:01:39" itemprop="dateCreated datePublished" datetime="2020-03-04T12:08:25+08:00">2020-03-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hey"><a href="#Hey" class="headerlink" title="Hey"></a>Hey</h1><blockquote>
<p>Machine Learning notes</p>
</blockquote>
<h1 id="softmaxa-Regression"><a href="#softmaxa-Regression" class="headerlink" title="softmaxa Regression"></a>softmaxa Regression</h1><p>为LR在多分类上的推广，与LR一样，同属于广义线性模型（Generalized Linear Model）</p>
<p>​    </p>
<script type="math/tex; mode=display">
S_i=\frac{e^{V_i}}{\sum_i^Ce^{V_i}}</script><p>其中，Vi 是分类器前级输出单元的输出。i 表示类别索引，总的类别个数为 C。Si 表示的是当前元素的指数与所有元素指数和的比值。Softmax 将多分类的输出数值转化为相对概率，更容易理解和比较。我们来看下面这个例子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 什么是Softmax函数</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">实际应用中，使用 Softmax 需要注意数值溢出的问题。因为有指数运算，</span></span><br><span class="line"><span class="string">如果 V 数值很大，经过指数运算后的数值往往可能有溢出的可能。</span></span><br><span class="line"><span class="string">所以，需要对 V 进行一些数值处理：即 V 中的每个元素减去 V 中的最大值。"""</span></span><br><span class="line">scores = np.array([<span class="number">123</span>,<span class="number">456</span>,<span class="number">789</span>])</span><br><span class="line">scores -= np.max(scores)</span><br><span class="line">p = np.exp(scores) / np.sum(np.exp(scores))</span><br><span class="line"><span class="comment"># print(p)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Softmax损失函数</span></span><br><span class="line"><span class="comment"># 其中，Syi是正确类别对应的线性得分函数，Si 是正确类别对应的 Softmax输出。</span></span><br><span class="line"><span class="comment"># 由于 log 运算符不会影响函数的单调性，我们对 Si 进行 log 操作：</span></span><br><span class="line"><span class="comment"># 我们希望 Si 越大越好，即正确类别对应的相对概率越大越好，那么就可以对 Si 前面加个负号，来表示损失函数</span></span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
L_i=-log\frac{e^{S_{y_i}}}{\sum_{j=1}^Ce^{S_j}}=-(s_{y_i}-log\sum_{j=1}^Ce^{s_j})=-s_{y_i}+log\sum_{j=1}^Ce^{s_j}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax_loss_naive</span><span class="params">(W,X,y,reg)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Softmax loss function ,naive implementation(with loops)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs have dimension D,there are C classes,and we operate on minibatches of N examples</span></span><br><span class="line"><span class="string">    :param W: A numpy array of shape(D,C) containing weights</span></span><br><span class="line"><span class="string">    :param X: A numpy array of shaep(N,D) containing a minibatch of data</span></span><br><span class="line"><span class="string">    :param y:A numpy array of shape(N,) containing training,labels,y[i] = c means</span></span><br><span class="line"><span class="string">    :param reg:(float) regularization strength</span></span><br><span class="line"><span class="string">    :return: A tuple of (loss as single float, gradient with respect to weights W,an array of same shape as  W)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># initialize the loss and gradient to zero</span></span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    dW = np.zeros_like(W)</span><br><span class="line"></span><br><span class="line">    num_train = X.shape[<span class="number">0</span>]</span><br><span class="line">    num_classes = W.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_train):</span><br><span class="line">        scores = X[i,:].dot(W)</span><br><span class="line">        scores_shift = scores - np.max(scores)</span><br><span class="line">        right_class = y[i]</span><br><span class="line">        loss += (-scores_shift[right_class] + np.log(np.sum(np.exp(scores_shift))))</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(num_classes):</span><br><span class="line">            softmax_output = np.exp(scores_shift[j]) / np.sum(np.exp(scores_shift))</span><br><span class="line">            <span class="keyword">if</span> j == y[i]:</span><br><span class="line">                dW[:,j] += (<span class="number">-1</span> + softmax_output) * X[i,:]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dW[:,j] += softmax_output * X[i,:]</span><br><span class="line">    loss /= num_train</span><br><span class="line">    loss += <span class="number">0.5</span> * reg * np.sum(W*W)</span><br><span class="line">    dW /= num_train</span><br><span class="line">    dW += reg * W</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss,dW</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax_loss_vectorized</span><span class="params">(W,X,y,reg)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Softmax loss function,vectorized version</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs and outputs are the same as softmax_loss_naive</span></span><br><span class="line"><span class="string">    :param W:</span></span><br><span class="line"><span class="string">    :param X:</span></span><br><span class="line"><span class="string">    :param y:</span></span><br><span class="line"><span class="string">    :param reg:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    dW = np.zeros_like(W)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获得样本的数量</span></span><br><span class="line">    num_train = X.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 获取样本的分裂数量</span></span><br><span class="line">    num_classes = W.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 获取到每个样本所对应的分类的得分</span></span><br><span class="line">    scores = X.dot(W)</span><br><span class="line">    scores_shift = scores - np.max(scores, axis=<span class="number">1</span>)</span><br><span class="line">    softmax_output = np.exp(scores_shift) / np.sum(np.exp(scores_shift), axis=<span class="number">1</span>)</span><br><span class="line">    loss = -np.sum(np.log(softmax_output[range(num_train), list(y)]))</span><br><span class="line">    loss /= num_train</span><br><span class="line">    loss += <span class="number">0.5</span> * reg * np.sum(W * W)</span><br><span class="line"></span><br><span class="line">    dS = softmax_output.copy()</span><br><span class="line">    dS[range(num_train), list(y)] += <span class="number">-1</span></span><br><span class="line">    dW = (X.T).dot(dS)</span><br><span class="line">    dW = dW / num_train + reg * W</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LelandYan"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">LelandYan</p>
  <div class="site-description" itemprop="description">涉猎的主要编程语言为 Python、matlab、C++、java，领域涵盖机器学校、爬虫、深度学习、python相关网页制作等。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">31</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LelandYan</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.2
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.getAttribute('pjax') !== null) {
      script.setAttribute('pjax', '');
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


    </div>
</body>
</html>
